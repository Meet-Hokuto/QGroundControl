% 1
@INPROCEEDINGS{990992, 
author={J. P. Barreto and H. Araujo}, 
booktitle={Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, 
title={Issues on the geometry of central catadioptric image formation}, 
year={2001}, 
volume={2}, 
number={}, 
pages={II-II}, 
keywords={computer vision;mirrors;computational geometry;central catadioptric image formation geometry;imaging system;central projection system;conventional perspective camera;mirrors;unique center of projection;perspective image formation;linear model;linear function;oriented projective plane;nonlinear transformation;collineation;projection of lines;geometric properties;auto-calibration;line images;Cameras;Mirrors;Nonlinear equations;Application software;Data mining;Computational geometry;Robot vision systems;Computer vision;Surveillance;Virtual reality}, 
doi={10.1109/CVPR.2001.990992}, 
ISSN={1063-6919}, 
month={Dec},}

% 2
@INPROCEEDINGS{7892326,
author = {E. Z. Borba and A. Montes and R. de Deus Lopes and M. K. Zuffo and R. Kopper},
booktitle = {2017 IEEE Virtual Reality (VR)},
title = {Itapeva 3D: Being Indiana Jones in virtual reality},
year = {2017},
volume = {00},
number = {},
pages = {361-362},
keywords={Three-dimensional displays;Solid modeling;Visualization;Rocks;Virtual environments;Laser modes},
doi = {10.1109/VR.2017.7892326},
url = {doi.ieeecomputersociety.org/10.1109/VR.2017.7892326},
ISSN = {2375-5334},
month={}
}

% 3
@article{DBLP:journals/corr/CherpillodMF17,
  author    = {Alexandre Cherpillod and
               Stefano Mintchev and
               Dario Floreano},
  title     = {Embodied Flight with a Drone},
  journal   = {CoRR},
  volume    = {abs/1707.01788},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.01788},
  archivePrefix = {arXiv},
  eprint    = {1707.01788},
  timestamp = {Mon, 13 Aug 2018 16:46:32 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/CherpillodMF17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

% 4
@INPROCEEDINGS{7502665,
author={R. A. S. {Fernández} and J. L. {Sanchez-Lopez} and C. {Sampedro} and H. {Bavle} and M. {Molina} and P. {Campoy}},
booktitle={2016 International Conference on Unmanned Aircraft Systems (ICUAS)},
title={Natural user interfaces for human-drone multi-modal interaction},
year={2016},
volume={},
number={},
pages={1013-1022},
keywords={aerospace computing;aerospace robotics;control engineering computing;gesture recognition;graphical user interfaces;helicopters;human-robot interaction;image sensors;microphones;mobile robots;motion control;robot vision;speech-based user interfaces;user centred design;natural user interfaces;human-drone multimodal interaction;personal drones;aerial systems;user-centered design;USD;NUI;graphical user interface;GUI;computer vision techniques;single software framework;aerial robotics;Aerostack;natural human-quadrotor interaction;indoor GPS-denied environments;speech interaction;body position interaction;hand gesture interaction;visual marker interaction;leap motion controller;microphones;small size monocular on-board cameras;Drones;Graphical user interfaces;Robot sensing systems;Cameras;Speech},
doi={10.1109/ICUAS.2016.7502665},
ISSN={null},
month={June},}

% 5
@article{doi:10.1177/154193120605000909,
author = {Sandra G. Hart},
title ={Nasa-Task Load Index (NASA-TLX); 20 Years Later},
journal = {Proceedings of the Human Factors and Ergonomics Society Annual Meeting},
volume = {50},
number = {9},
pages = {904-908},
year = {2006},
doi = {10.1177/154193120605000909},
URL = { 
        https://doi.org/10.1177/154193120605000909
},
eprint = { 
        https://doi.org/10.1177/154193120605000909
}
,
    abstract = { NASA-TLX is a multi-dimensional scale designed to obtain workload estimates from one or more operators while they are performing a task or immediately afterwards. The years of research that preceded subscale selection and the weighted averaging approach resulted in a tool that has proven to be reasonably easy to use and reliably sensitive to experimentally important manipulations over the past 20 years. Its use has spread far beyond its original application (aviation), focus (crew complement), and language (English). This survey of 550 studies in which NASA-TLX was used or reviewed was undertaken to provide a resource for a new generation of users. The goal was to summarize the environments in which it has been applied, the types of activities the raters performed, other variables that were measured that did (or did not) covary, methodological issues, and lessons learned }
}

% 6
@inproceedings{Hayakawa:2015:TDD:2735711.2735816,
 author = {Hayakawa, Hirohiko and Fernando, Charith Lasantha and Saraiji, MHD Yamen and Minamizawa, Kouta and Tachi, Susumu},
 title = {Telexistence Drone: Design of a Flight Telexistence System for Immersive Aerial Sports Experience},
 booktitle = {Proceedings of the 6th Augmented Human International Conference},
 series = {AH '15},
 year = {2015},
 isbn = {978-1-4503-3349-8},
 location = {Singapore, Singapore},
 pages = {171--172},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2735711.2735816},
 doi = {10.1145/2735711.2735816},
 acmid = {2735816},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {aerial sports, augmented sports, drone telexistence, flight experience, virtual reality},
} 
% 7
@article{mci/Herrmann2018,
author = {Herrmann, Roman AND Schmidt, Ludger},
title = {Design and Evaluation of a Natural User Interface for Piloting an Unmanned Aerial Vehicle},
journal = {i-com},
volume = {17},
number = {1},
year = {2018},
pages = { 15-24 }
}

% 8 
@inproceedings{Higuchi:2013:FHH:2468356.2468721,
 author = {Higuchi, Keita and Rekimoto, Jun},
 title = {Flying Head: A Head Motion Synchronization Mechanism for Unmanned Aerial Vehicle Control},
 booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
 series = {CHI EA '13},
 year = {2013},
 isbn = {978-1-4503-1952-2},
 location = {Paris, France},
 pages = {2029--2038},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2468356.2468721},
 doi = {10.1145/2468356.2468721},
 acmid = {2468721},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {telepresence, unmanned aerial vehicle},
}

% 9
@article {PMID:29364873,
	Title = {Small-scale soft-bodied robot with multimodal locomotion},
	Author = {Hu, Wenqi and Lum, Guo Zhan and Mastrangeli, Massimo and Sitti, Metin},
	DOI = {10.1038/nature25443},
	Number = {7690},
	Volume = {554},
	Month = {February},
	Year = {2018},
	Journal = {Nature},
	ISSN = {0028-0836},
	Pages = {81-85},
	URL = {https://doi.org/10.1038/nature25443},
}

% 10
@INPROCEEDINGS{7892318, 
author={Y. Inoue and F. Kato and M. Y. Saraiji and C. L. Fernando and S. Tachi}, 
booktitle={2017 IEEE Virtual Reality (VR)}, 
title={Observation of mirror reflection and voluntary self-touch enhance self-recognition for a telexistence robot}, 
year={2017}, 
volume={}, 
number={}, 
pages={345-346}, 
keywords={control engineering computing;telerobotics;virtual reality;mirror reflection;voluntary self-touch;telexistence robot;robot self-recognition;subjective feelings;surrogate robot avata;virtual reality experiment;tactile sensations;Mirrors;Robot sensing systems;Delays;Face;Virtual reality;Correlation;telexistence;body ownership;agency;self-touch;mirror recognition}, 
doi={10.1109/VR.2017.7892318}, 
ISSN={2375-5334}, 
month={March},}

% 11
@inproceedings{Kasahara:2015:JHI:2821592.2821608,
 author = {Kasahara, Shunichi and Rekimoto, Jun},
 title = {JackIn Head: Immersive Visual Telepresence System with Omnidirectional Wearable Camera for Remote Collaboration},
 booktitle = {Proceedings of the 21st ACM Symposium on Virtual Reality Software and Technology},
 series = {VRST '15},
 year = {2015},
 isbn = {978-1-4503-3990-2},
 location = {Beijing, China},
 pages = {217--225},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/2821592.2821608},
 doi = {10.1145/2821592.2821608},
 acmid = {2821608},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {first-person view, omnidirectional video, remote collaboration, telepresence, wearable camera},
}

% 12
@article{KIM201482,
title = "Quadcopter flight control using a low-cost hybrid interface with EEG-based classification and eye tracking",
journal = "Computers in Biology and Medicine",
volume = "51",
pages = "82 - 92",
year = "2014",
issn = "0010-4825",
doi = "https://doi.org/10.1016/j.compbiomed.2014.04.020",
url = "http://www.sciencedirect.com/science/article/pii/S0010482514001061",
author = "Byung Hyung Kim and Minho Kim and Sungho Jo",
keywords = "Hybrid interface, Brain鈥揷omputer interface, Mental concentration, Eye tracking, Quadcopter flight control",
abstract = "We propose a wearable hybrid interface where eye movements and mental concentration directly influence the control of a quadcopter in three-dimensional space. This noninvasive and low-cost interface addresses limitations of previous work by supporting users to complete their complicated tasks in a constrained environment in which only visual feedback is provided. The combination of the two inputs augments the number of control commands to enable the flying robot to travel in eight different directions within the physical environment. Five human subjects participated in the experiments to test the feasibility of the hybrid interface. A front view camera on the hull of the quadcopter provided the only visual feedback to each remote subject on a laptop display. Based on the visual feedback, the subjects used the interface to navigate along pre-set target locations in the air. The flight performance was evaluated by comparing with a keyboard-based interface. We demonstrate the applicability of the hybrid interface to explore and interact with a three-dimensional physical space through a flying robot."
}

% 13	
@article{1741-2552-10-4-046003,
  author={Karl LaFleur and Kaitlin Cassady and Alexander Doud and Kaleb Shades and Eitan Rogin and Bin He},
  title={Quadcopter control in three-dimensional space using a noninvasive
motor imagery-based brain–computer interface},
  journal={Journal of Neural Engineering},
  volume={10},
  number={4},
  pages={046003},
  url={http://stacks.iop.org/1741-2552/10/i=4/a=046003},
  year={2013},
  abstract={Objective. At the balanced intersection of human and machine adaptation is found the optimally functioning brain鈥揷omputer interface (BCI). In this study, we report a novel experiment of BCI controlling a robotic quadcopter in three-dimensional (3D) physical space using noninvasive scalp electroencephalogram (EEG) in human subjects. We then quantify the performance of this system using metrics suitable for asynchronous BCI. Lastly, we examine the impact that the operation of a real world device has on subjects' control in comparison to a 2D virtual cursor task. Approach. Five human subjects were trained to modulate their sensorimotor rhythms to control an AR Drone navigating a 3D physical space. Visual feedback was provided via a forward facing camera on the hull of the drone. Main results. Individual subjects were able to accurately acquire up to 90.5% of all valid targets presented while travelling at an average straight-line speed of 0.69聽m s 鈭? . Significance. Freely exploring and interacting with the world around us is a crucial element of autonomy that is lost in the context of neurodegenerative disease. Brain鈥揷omputer interfaces are systems that aim to restore or enhance a user's ability to interact with the environment via a computer and through the use of only thought. We demonstrate for the first time the ability to control a flying robot in 3D physical space using noninvasive scalp recorded EEG in humans. Our work indicates the potential of noninvasive EEG-based BCI systems for accomplish complex control in 3D physical space. The present study may serve as a framework for the investigation of multidimensional noninvasive BCI control in a physical environment using telepresence robotics.}
}

% 14
@article {Miehlbradt7913,
	author = {Miehlbradt, Jenifer and Cherpillod, Alexandre and Mintchev, Stefano and Coscia, Martina and Artoni, Fiorenzo and Floreano, Dario and Micera, Silvestro},
	title = {Data-driven body{\textendash}machine interface for the accurate control of drones},
	volume = {115},
	number = {31},
	pages = {7913--7918},
	year = {2018},
	doi = {10.1073/pnas.1718648115},
	publisher = {National Academy of Sciences},
	abstract = {The teleoperation of nonhumanoid robots is often a demanding task, as most current control interfaces rely on mappings between the operator{\textquoteright}s and the robot{\textquoteright}s actions, which are determined by the design and characteristics of the interface, and may therefore be challenging to master. Here, we describe a structured methodology to identify common patterns in spontaneous interaction behaviors, to implement embodied user interfaces, and to select the appropriate sensor type and positioning. Using this method, we developed an intuitive, gesture-based control interface for real and simulated drones, which outperformed a standard joystick in terms of learning time and steering abilities. Implementing this procedure to identify body-machine patterns for specific applications could support the development of more intuitive and effective interfaces.The accurate teleoperation of robotic devices requires simple, yet intuitive and reliable control interfaces. However, current human{\textendash}machine interfaces (HMIs) often fail to fulfill these characteristics, leading to systems requiring an intensive practice to reach a sufficient operation expertise. Here, we present a systematic methodology to identify the spontaneous gesture-based interaction strategies of naive individuals with a distant device, and to exploit this information to develop a data-driven body{\textendash}machine interface (BoMI) to efficiently control this device. We applied this approach to the specific case of drone steering and derived a simple control method relying on upper-body motion. The identified BoMI allowed participants with no prior experience to rapidly master the control of both simulated and real drones, outperforming joystick users, and comparing with the control ability reached by participants using the bird-like flight simulator Birdly.},
	issn = {0027-8424},
	URL = {http://www.pnas.org/content/115/31/7913},
	eprint = {http://www.pnas.org/content/115/31/7913.full.pdf},
	journal = {Proceedings of the National Academy of Sciences}
}

% 15
@INPROCEEDINGS{7625774, 
author={S. Park and Y. Jung and J. Bae}, 
booktitle={2016 13th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)}, 
title={A tele-operation interface with a motion capture system and a haptic glove}, 
year={2016}, 
volume={}, 
number={}, 
pages={544-549}, 
keywords={3G mobile communication;data gloves;dexterous manipulators;human-robot interaction;inertial systems;Long Term Evolution;motion estimation;robot kinematics;telerobotics;vibrations;virtual private networks;teleoperation interface;motion capture system;haptic glove;teleoperation systems;nonintuitive control interfaces;joystick;keyboard;wireless communication;inertial measurement units;IMU;six degrees of freedom robot arm;six DOF robot arm;forward kinematics;robot joint angles;inverse kinematics;grasp force;tele-communication method;3rd generation partnership project long term evolution network;3GPP LTE network;virtual private network;VPN;Virtual private networks;Kinematics;Long Term Evolution;Manipulators;Servers;Indexes;Tele-operation;Motion capture;Human-robot interaction;Robot arm}, 
doi={10.1109/URAI.2016.7625774}, 
ISSN={}, 
month={Aug},}

% 16
@inproceedings{Pfeil:2013:EGM:2449396.2449429,
 author = {Pfeil, Kevin and Koh, Seng Lee and LaViola, Joseph},
 title = {Exploring 3D Gesture Metaphors for Interaction with Unmanned Aerial Vehicles},
 booktitle = {Proceedings of the 2013 International Conference on Intelligent User Interfaces},
 series = {IUI '13},
 year = {2013},
 isbn = {978-1-4503-1965-2},
 location = {Santa Monica, California, USA},
 pages = {257--266},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2449396.2449429},
 doi = {10.1145/2449396.2449429},
 acmid = {2449429},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3d interaction, robots, user studies},
}

% 17 
@inproceedings{Pittman:2014:EHT:2557500.2557527,
 author = {Pittman, Corey and LaViola,Jr., Joseph J.},
 title = {Exploring Head Tracked Head Mounted Displays for First Person Robot Teleoperation},
 booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
 series = {IUI '14},
 year = {2014},
 isbn = {978-1-4503-2184-6},
 location = {Haifa, Israel},
 pages = {323--328},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2557500.2557527},
 doi = {10.1145/2557500.2557527},
 acmid = {2557527},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3d interaction, robots, user studies},
}

% 18
@ARTICLE{6261311, 
author={E. D. Ragan and R. Kopper and P. Schuchardt and D. A. Bowman}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Studying the Effects of Stereo, Head Tracking, and Field of Regard on a Small-Scale Spatial Judgment Task}, 
year={2013}, 
volume={19}, 
number={5}, 
pages={886-896}, 
keywords={rendering (computer graphics);stereo image processing;virtual reality;complex 3D structure;spatial understanding task;virtual reality;small-scale spatial judgment task;head-tracked rendering;stereoscopy;Visualization;Electron tubes;Navigation;Data visualization;Head;Tracking;Rendering (computer graphics);Artificial;augmented;and virtual realities;graphical user interfaces;Adolescent;Adult;Aged;Cues;Depth Perception;Female;Head Movements;Humans;Male;Middle Aged;Orientation;Psychomotor Performance;Space Perception;Visual Fields;Young Adult}, 
doi={10.1109/TVCG.2012.163}, 
ISSN={1077-2626}, 
month={May},}

% 19
@ARTICLE{8304759, 
author={C. Rognon and S. Mintchev and F. Dell'Agnola and A. Cherpillod and D. Atienza and D. Floreano}, 
journal={IEEE Robotics and Automation Letters}, 
title={FlyJacket: An Upper Body Soft Exoskeleton for Immersive Drone Control}, 
year={2018}, 
volume={3}, 
number={3}, 
pages={2362-2369}, 
keywords={autonomous aerial vehicles;biomechanics;computerised monitoring;gesture recognition;handicapped aids;interactive devices;mobile robots;motion control;patient monitoring;robot vision;telecontrol;participants;fixed-wing drone;drone perspective;fatigue;arm support system;body movements;motion-tracking device;intuitive manner;upper body gestures;naïve users;wearable interfaces;teleoperation;developed skills;remote controller;human-drone interfaces;immersive drone control;upper body soft exoskeleton;FlyJacket;Drones;Fabrics;Exoskeletons;Torso;Fatigue;Manipulators;Human-robot interaction;telerobotics and teleoperation;virtual reality and interfaces;wearable robots}, 
doi={10.1109/LRA.2018.2810955}, 
ISSN={2377-3766}, 
month={July},}

% 20
@incollection{HART1988139,
title = "Development of NASA-TLX (Task Load Index): Results of Empirical and Theoretical Research",
editor = "Peter A. Hancock and Najmedin Meshkati",
series = "Advances in Psychology",
publisher = "North-Holland",
volume = "52",
pages = "139 - 183",
year = "1988",
booktitle = "Human Mental Workload",
issn = "0166-4115",
doi = "https://doi.org/10.1016/S0166-4115(08)62386-9",
url = "http://www.sciencedirect.com/science/article/pii/S0166411508623869",
author = "Sandra G. Hart and Lowell E. Staveland",
abstract = "The results of a multi-year research program to identify the factors associated with variations in subjective workload within and between different types of tasks are reviewed. Subjective evaluations of 10 workload-related factors were obtained from 16 different experiments. The experimental tasks included simple cognitive and manual control tasks, complex laboratory and supervisory control tasks, and aircraft simulation. Task-, behavior-, and subject-related correlates of subjective workload experiences varied as a function of difficulty manipulations within experiments, different sources of workload between experiments, and individual differences in workload definition. A multi-dimensional rating scale is proposed in which information about the magnitude and sources of six workload-related factors are combined to derive a sensitive and reliable estimate of workload."
}

% 21
@article{SANNA2013179,
title = "A Kinect-based natural interface for quadrotor control",
journal = "Entertainment Computing",
volume = "4",
number = "3",
pages = "179 - 186",
year = "2013",
issn = "1875-9521",
doi = "https://doi.org/10.1016/j.entcom.2013.01.001",
url = "http://www.sciencedirect.com/science/article/pii/S1875952113000025",
author = "Andrea Sanna and Fabrizio Lamberti and Gianluca Paravati and Federico Manuri",
keywords = "Natural user interface, Kinect, Quadrotor control, Interactive systems, Visual odometry",
abstract = "This paper presents a new and challenging approach to the control of mobile platforms. Natural user interfaces (NUIs) and visual computing techniques are used to control the navigation of a quadrotor in GPS-denied indoor environments. A visual odometry algorithm allows the platform to autonomously navigate the environment, whereas the user can control complex manoeuvres by gestures and body postures. This approach makes the human–computer interaction (HCI) more intuitive, usable, and receptive to the user’s needs: in other words, more user-friendly and, why not, fun. The NUI presented in this paper is based on the Microsoft Kinect and users can customize the association among gestures/postures and platform commands, thus choosing the more intuitive and effective interface."
}

% 22
@ARTICLE{7587429, 
author={C. Semini and V. Barasuol and J. Goldsmith and M. Frigerio and M. Focchi and Y. Gao and D. G. Caldwell}, 
journal={IEEE/ASME Transactions on Mechatronics}, 
title={Design of the Hydraulically Actuated, Torque-Controlled Quadruped Robot HyQ2Max}, 
year={2017}, 
volume={22}, 
number={2}, 
pages={635-646}, 
keywords={hydraulic actuators;legged locomotion;motion control;robot kinematics;torque control;hydraulically actuated robot;torque-controlled quadruped robot design;HyQ2Max;HyQ robot;locomotion skills;self-righting capability;robot actuation system;joint actuator sizing;robot motion;agile rough terrain robot;terrain trotting;stair climbing motion;push recovery motion;hydraulic actuator types;four-bar linkage parameters;valve size;terrain crawling;hydraulic cylinder parameters;robot kinematics;Legged locomotion;Actuators;Couplings;Vehicle dynamics;Biological system modeling;Mechatronics;Hydraulic actuation;HyQ2Max;legged locomotion;quadruped robot design}, 
doi={10.1109/TMECH.2016.2616284}, 
ISSN={1083-4435}, 
month={April},}

% 23
@article{SHIBATA200257,
title = "Head mounted display",
journal = "Displays",
volume = "23",
number = "1",
pages = "57 - 64",
year = "2002",
issn = "0141-9382",
doi = "https://doi.org/10.1016/S0141-9382(02)00010-0",
url = "http://www.sciencedirect.com/science/article/pii/S0141938202000100",
author = "Takashi Shibata",
keywords = "Head mounted displays, Accommodation, Convergence, Stereoscopic images, Simulation system",
abstract = "This chapter describes head mounted displays (HMDs) from the viewpoint of the human factors. Because it has two separate display systems, HMDs are especially effective in displaying stereoscopic images. To develop better stereoscopic three-dimensional display technologies, it is important to investigate visual functions such as accommodation and convergence. From the results of the experiments, it is now possible to establish the proper settings for HMD devices to reduce the visual load. An example of the industrial application of an HMD is illustrated."
}

% 24
@INPROCEEDINGS{7846875, 
author={X. Song and K. Mann and E. Allison and S. Yoon and H. Hila and A. Muller and C. Gieder}, 
booktitle={2016 IEEE Signal Processing in Medicine and Biology Symposium (SPMB)}, 
title={A quadcopter controlled by brain concentration and eye blink}, 
year={2016}, 
volume={}, 
number={}, 
pages={1-4}, 
keywords={brain-computer interfaces;control engineering computing;electroencephalography;helicopters;signal processing;quadcopter;brain concentration;eye blink;brain computer interface;BCI;signal analysis;neural activity;electroencephalography;EEG;Electroencephalography;Computers;Headphones;Data processing;Process control;Feature extraction;Art}, 
doi={10.1109/SPMB.2016.7846875}, 
ISSN={}, 
month={Dec},}

% 25
@ARTICLE{734972, 
author={S. Tachi}, 
journal={IEEE Computer Graphics and Applications}, 
title={Real-time remote robotics-toward networked telexistence}, 
year={1998}, 
volume={18}, 
number={6}, 
pages={6-9}, 
keywords={telerobotics;virtual reality;real-time systems;computer networks;Internet;remote environment;remote robotics;networked telexistence;virtual reality;networked robotics;mutual telexistence;Internet;Control systems;Robotics and automation;Robot sensing systems;Computer displays;Virtual environment;Automatic control;Motion control;Pressure control;Human robot interaction;Pulse measurements}, 
doi={10.1109/38.734972}, 
ISSN={0272-1716}, 
month={Nov},}

% 26
@ARTICLE{7383142,
author = {S. Tachi},
journal = {IEEE Computer Graphics and Applications},
title = {Telexistence: Enabling Humans to Be Virtually Ubiquitous},
year = {2016},
volume = {36},
number = {1},
pages = {8-14},
keywords={Spatial analysis;Haptic interfaces;Human factors;Robots;Remote sensing},
doi = {10.1109/MCG.2016.6},
url = {doi.ieeecomputersociety.org/10.1109/MCG.2016.6},
ISSN = {0272-1716},
month={Jan.-Feb.}
}

% 27
@ARTICLE{1512014, 
author={R. Tadakuma and Y. Asahara and H. Kajimoto and N. Kawakami and S. Tachi}, 
journal={IEEE Transactions on Visualization and Computer Graphics}, 
title={Development of anthropomorphic multi-D.O.F master-slave arm for mutual telexistence}, 
year={2005}, 
volume={11}, 
number={6}, 
pages={626-636}, 
keywords={gesture recognition;virtual reality;force feedback;dexterous manipulators;telerobotics;anthropomorphic multi-D.O.F master-slave arm development;mutual telexistence robot;robotic arm;remote dexterous manipulation;close physical communication;gesture;interpersonal communication;virtual reality;force feedback;bilateral impedance control method;Anthropomorphism;Master-slave;Robot sensing systems;Impedance;Communication system control;Humanoid robots;Service robots;Humans;Arm;Orbital robotics;Index Terms- Telexistence;virtual reality;force feedback;bilateral impedance control.;Arm;Biomimetic Materials;Bionics;Bionics;Computer Simulation;Cybernetics;Cybernetics;Environment;Equipment Design;Equipment Failure Analysis;Humans;Joints;Man-Machine Systems;Models, Biological;Robotics;Robotics;User-Computer Interface}, 
doi={10.1109/TVCG.2005.99}, 
ISSN={1077-2626}, 
month={Nov},}

% 28
@inproceedings{Ying2004Can,
  title={Can We Consider Central Catadioptric Cameras and Fisheye Cameras within a Unified Imaging Model},
  author={Ying, Xianghua and Hu, Zhanyi},
  booktitle={European Conference on Computer Vision},
  pages={442-455},
  year={2004},
}

% 29
@INPROCEEDINGS{Wells96thevirtual,
    author = {Maxwell J. Wells and Barry N. Peterson and Jason Aten},
    title = {The virtual motion controller: a sufficient-motion walking simulator},
    booktitle = {In Proceedings of VRAIS '97},
    year = {1996},
    pages = {1--8}
}

% 30
@inproceedings{Poupyrev:1996:GIT:237091.237102,
 author = {Poupyrev, Ivan and Billinghurst, Mark and Weghorst, Suzanne and Ichikawa, Tadao},
 title = {The Go-go Interaction Technique: Non-linear Mapping for Direct Manipulation in VR},
 booktitle = {Proceedings of the 9th Annual ACM Symposium on User Interface Software and Technology},
 series = {UIST '96},
 year = {1996},
 isbn = {0-89791-798-7},
 location = {Seattle, Washington, USA},
 pages = {79--80},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/237091.237102},
 doi = {10.1145/237091.237102},
 acmid = {237102},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D user interface, user interface metaphor, virtual reality},
} 
% 31
@inproceedings{Bowman:1997:ETG:253284.253301,
 author = {Bowman, Doug A. and Hodges, Larry F.},
 title = {An Evaluation of Techniques for Grabbing and Manipulating Remote Objects in Immersive Virtual Environments},
 booktitle = {Proceedings of the 1997 Symposium on Interactive 3D Graphics},
 series = {I3D '97},
 year = {1997},
 isbn = {0-89791-884-3},
 location = {Providence, Rhode Island, USA},
 pages = {35--ff.},
 url = {http://doi.acm.org/10.1145/253284.253301},
 doi = {10.1145/253284.253301},
 acmid = {253301},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% 32
@article{Zhai:1998:UPR:307710.307728,
 author = {Zhai, Shumin},
 title = {User Performance in Relation to 3D Input Device Design},
 journal = {SIGGRAPH Comput. Graph.},
 issue_date = {Nov. 1998},
 volume = {32},
 number = {4},
 month = nov,
 year = {1998},
 issn = {0097-8930},
 pages = {50--54},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/307710.307728},
 doi = {10.1145/307710.307728},
 acmid = {307728},
 publisher = {ACM},
 address = {New York, NY, USA},
}

% 33
@inproceedings{Besancon:2017:PGF:3025453.3025890,
 author = {Besan\c{c}on, Lonni and Ammi, Mehdi and Isenberg, Tobias},
 title = {Pressure-Based Gain Factor Control for Mobile 3D Interaction Using Locally-Coupled Devices},
 booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {1831--1842},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3025453.3025890},
 doi = {10.1145/3025453.3025890},
 acmid = {3025890},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3D navigation, TUI, pressure input, tangible interaction},
}

% 34
@article{Konrad:2017:STL:3130800.3130836,
 author = {Konrad, Robert and Dansereau, Donald G. and Masood, Aniq and Wetzstein, Gordon},
 title = {SpinVR: Towards Live-streaming 3D Virtual Reality Video},
 journal = {ACM Trans. Graph.},
 issue_date = {November 2017},
 volume = {36},
 number = {6},
 month = nov,
 year = {2017},
 issn = {0730-0301},
 pages = {209:1--209:12},
 articleno = {209},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3130800.3130836},
 doi = {10.1145/3130800.3130836},
 acmid = {3130836},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {computational photography, omnidirectional stereo, real-time, virtual reality},
}

% 35 UAV mapping综述
@Article{Nex2014,
author="Nex, Francesco
and Remondino, Fabio",
title="UAV for 3D mapping applications: a review",
journal="Applied Geomatics",
year="2014",
month="Mar",
day="01",
volume="6",
number="1",
pages="1--15",
abstract="Unmanned aerial vehicle (UAV) platforms are nowadays a valuable source of data for inspection, surveillance, mapping, and 3D modeling issues. As UAVs can be considered as a low-cost alternative to the classical manned aerial photogrammetry, new applications in the short- and close-range domain are introduced. Rotary or fixed-wing UAVs, capable of performing the photogrammetric data acquisition with amateur or SLR digital cameras, can fly in manual, semiautomated, and autonomous modes. Following a typical photogrammetric workflow, 3D results like digital surface or terrain models, contours, textured 3D models, vector information, etc. can be produced, even on large areas. The paper reports the state of the art of UAV for geomatics applications, giving an overview of different UAV platforms, applications, and case studies, showing also the latest developments of UAV image processing. New perspectives are also addressed.",
issn="1866-928X",
doi="10.1007/s12518-013-0120-x",
url="https://doi.org/10.1007/s12518-013-0120-x"
}


% 36 
% Trans-scale Playground: An Immersive Visual Telexistence System for Human 
Adaptation
% 37
@INPROCEEDINGS{8574612, 
author={H. {Abe} and M. {Miura} and T. {Abe} and T. {Suganuma}}, 
booktitle={2018 IEEE 7th Global Conference on Consumer Electronics (GCCE)}, 
title={A Telexistence System Using Remote Control Robot and Omnidirectional Camera with QoE Control}, 
year={2018}, 
volume={}, 
number={}, 
pages={1-3}, 
keywords={cameras;control engineering computing;mobile robots;quality of experience;robot vision;telerobotics;video signal processing;virtual reality;telexistence system;remote control robot;omnidirectional camera;QoE control;received video image;realism;operability;robots operational action;users quality of experience;Cameras;Robot vision systems;Quality of experience;Remote control;Delays;Telexistence}, 
doi={10.1109/GCCE.2018.8574612}, 
ISSN={2378-8143}, 
month={Oct},}

% 38 双目重建
@INPROCEEDINGS{5940405, 
author={A. {Geiger} and J. {Ziegler} and C. {Stiller}}, 
booktitle={2011 IEEE Intelligent Vehicles Symposium (IV)}, 
title={StereoScan: Dense 3d reconstruction in real-time}, 
year={2011}, 
volume={}, 
number={}, 
pages={963-968}, 
keywords={distance measurement;image matching;image reconstruction;image sequences;robot vision;stereo image processing;StereoScan;dense 3D reconstruction;video sequences;computer vision;robotics;scene analysis;camera resolution;3D maps;high resolution stereo sequences;stereo matching;feature matcher;robust visual odometry algorithm;multiview linking scheme;3D point clouds;Three dimensional displays;Visualization;Real time systems;Image reconstruction;Stereo image processing;Cameras;Estimation}, 
doi={10.1109/IVS.2011.5940405}, 
ISSN={1931-0587}, 
month={June},}

% 39 voxel hashing
@Article{niener2013real-time,
author = {Nießner, Matthias and Zollhöfer, Michael and Izadi, Shahram and Stamminger, Marc},
title = {Real-time 3D Reconstruction at Scale using Voxel Hashing},
year = {2013},
month = {January},
abstract = {Online 3D reconstruction is gaining newfound interest due to the availability of real-time consumer depth cameras. The basic problem takes live overlapping depth maps as input and incrementally fuses these into a single 3D model. This is challenging particularly when real-time performance is desired without trading quality or scale. We contribute an online system for large and fine scale volumetric reconstruction based on a memory and speed efficient data structure. Our system uses a simple spatial hashing scheme that compresses space, and allows for real-time access and updates of implicit surface data, without the need for a regular or hierarchical grid data structure. Surface data is only stored densely where measurements are observed. Additionally, data can be streamed efficiently in or out of the hash table, allowing for further scalability during sensor motion. We show interactive reconstructions of a variety of scenes, reconstructing both fine-grained details and large scale environments. We illustrate how all parts of our pipeline from depth map pre-processing, camera pose estimation, depth map fusion, and surface rendering are performed at real-time rates on commodity graphics hardware. We conclude with a comparison to current state-of-the-art online systems, illustrating improved performance and reconstruction quality.},
url = {https://www.microsoft.com/en-us/research/publication/real-time-3d-reconstruction-at-scale-using-voxel-hashing/},
journal = {ACM Transactions on Graphics (TOG)},
}

% 40 MVG
@book{Harltey2003Multiple,
  title={Multiple view geometry in computer vision (2. ed.)},
  author={Harltey, Andrew and Zisserman, Andrew},
  year={2003},
}

% 41 MVS
@article{CGV-052,
url = {http://dx.doi.org/10.1561/0600000052},
year = {2015},
volume = {9},
journal = {Foundations and Trends® in Computer Graphics and Vision},
title = {Multi-View Stereo: A Tutorial},
doi = {10.1561/0600000052},
issn = {1572-2740},
number = {1-2},
pages = {1-148},
author = {Yasutaka Furukawa and Carlos Hernández}
}

% 42 LSD-SLAM
@InProceedings{10.1007/978-3-319-10605-2_54,
author="Engel, Jakob
and Sch{\"o}ps, Thomas
and Cremers, Daniel",
editor="Fleet, David
and Pajdla, Tomas
and Schiele, Bernt
and Tuytelaars, Tinne",
title="LSD-SLAM: Large-Scale Direct Monocular SLAM",
booktitle="Computer Vision -- ECCV 2014",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="834--849",
abstract="We propose a direct (feature-less) monocular SLAM algorithm which, in contrast to current state-of-the-art regarding direct methods, allows to build large-scale, consistent maps of the environment. Along with highly accurate pose estimation based on direct image alignment, the 3D environment is reconstructed in real-time as pose-graph of keyframes with associated semi-dense depth maps. These are obtained by filtering over a large number of pixelwise small-baseline stereo comparisons. The explicitly scale-drift aware formulation allows the approach to operate on challenging sequences including large variations in scene scale. Major enablers are two key novelties: (1) a novel direct tracking method which operates on {\$}{\backslash}mathfrak{\{}sim{\}}(3){\$}, thereby explicitly detecting scale-drift, and (2) an elegant probabilistic solution to include the effect of noisy depth values into tracking. The resulting direct monocular SLAM system runs in real-time on a CPU.",
isbn="978-3-319-10605-2"
}

% 43 KinectFusion
@INPROCEEDINGS{6162880, 
author={R. A. {Newcombe} and S. {Izadi} and O. {Hilliges} and D. {Molyneaux} and D. {Kim} and A. J. {Davison} and P. {Kohi} and J. {Shotton} and S. {Hodges} and A. {Fitzgibbon}}, 
booktitle={2011 10th IEEE International Symposium on Mixed and Augmented Reality}, 
title={KinectFusion: Real-time dense surface mapping and tracking}, 
year={2011}, 
volume={}, 
number={}, 
pages={127-136}, 
keywords={Surface reconstruction;Cameras;Image reconstruction;Real time systems;Simultaneous localization and mapping;Iterative closest point algorithm;Three dimensional displays;Real-Time;Dense Reconstruction;Tracking;GPU;SLAM;Depth Cameras;Volumetric Representation;AR}, 
doi={10.1109/ISMAR.2011.6092378}, 
ISSN={}, 
month={Oct},}

% 44 voxel hierarchy
@article{Chen:2013:SRV:2461912.2461940,
 author = {Chen, Jiawen and Bautembach, Dennis and Izadi, Shahram},
 title = {Scalable Real-time Volumetric Surface Reconstruction},
 journal = {ACM Trans. Graph.},
 issue_date = {July 2013},
 volume = {32},
 number = {4},
 month = jul,
 year = {2013},
 issn = {0730-0301},
 pages = {113:1--113:16},
 articleno = {113},
 numpages = {16},
 url = {http://doi.acm.org/10.1145/2461912.2461940},
 doi = {10.1145/2461912.2461940},
 acmid = {2461940},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {GPU, hierarchical grid, kinect, real-time, scalability, streaming, volumetric surface reconstruction},
}

% 45 bundlefusion
@article{dai2017bundlefusion,
  title={BundleFusion: Real-time Globally Consistent 3D Reconstruction using On-the-fly Surface Re-integration},
  author={Dai, Angela and Nie{\ss}ner, Matthias and Zoll{\"o}fer, Michael and Izadi, Shahram and Theobalt, Christian},
  journal={ACM Transactions on Graphics 2017 (TOG)},
  year={2017}
}

% 46 HSV
@article{Smith:1978:CGT:965139.807361,
 author = {Smith, Alvy Ray},
 title = {Color Gamut Transform Pairs},
 journal = {SIGGRAPH Comput. Graph.},
 issue_date = {August 1978},
 volume = {12},
 number = {3},
 month = aug,
 year = {1978},
 issn = {0097-8930},
 pages = {12--19},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/965139.807361},
 doi = {10.1145/965139.807361},
 acmid = {807361},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Brightness, Color, Color transform, Gamut, Hue, Luminance, NTSC, Saturation, Value},
}

% 47
@inproceedings{qin2018online,
  title={Online Temporal Calibration for Monocular Visual-Inertial Systems},
  author={Qin, Tong and Shen, Shaojie},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={3662--3669},
  year={2018},
  organization={IEEE}
}


% 48 vins
@article{qin2017vins,
  title={VINS-Mono: A Robust and Versatile Monocular Visual-Inertial State Estimator},
  author={Qin, Tong and Li, Peiliang and Shen, Shaojie},
  journal={IEEE Transactions on Robotics}, 
  year={2018},
  volume={34}, 
  number={4}, 
  pages={1004-1020}
}

% 49 gazebo
@ARTICLE{7014315, 
author={C. E. {Agüero} and N. {Koenig} and I. {Chen} and H. {Boyer} and S. {Peters} and J. {Hsu} and B. {Gerkey} and S. {Paepcke} and J. L. {Rivero} and J. {Manzo} and E. {Krotkov} and G. {Pratt}}, 
journal={IEEE Transactions on Automation Science and Engineering}, 
title={Inside the Virtual Robotics Challenge: Simulating Real-Time Robotic Disaster Response}, 
year={2015}, 
volume={12}, 
number={2}, 
pages={494-506}, 
keywords={cloud computing;control engineering computing;digital simulation;humanoid robots;human-robot interaction;public domain software;rescue robots;virtual robotics challenge;VRC;real-time robotic disaster response;software framework;cloud-hosted robot simulation;task-oriented robot competition;real-time robot competition;Defense Advanced Research Projects Agency;DARPA;Gazebo simulator;open source robot simulator;multisensor robot;CloudSim tool;Web technology;human-in-the-loop robot control;human-robot interfaces;Atlas humanoid robot;Computers;Real-time systems;Robot sensing systems;Computational modeling;Computer architecture;Servers;Cloud robotics;real-time robot simulation;robotic disaster response}, 
doi={10.1109/TASE.2014.2368997}, 
ISSN={1545-5955}, 
month={April},}

% 50 percetage mtric
@article{Knapitsch2017,
    author    = {Arno Knapitsch and Jaesik Park and Qian-Yi Zhou and Vladlen Koltun},
    title     = {Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction},
    journal   = {ACM Transactions on Graphics},
    volume    = {36},
    number    = {4},
    year      = {2017},
}

% 51 distance metric
@Article{A2016,
author="Aan{\ae}s, Henrik
and Jensen, Rasmus Ramsb{\o}l
and Vogiatzis, George
and Tola, Engin
and Dahl, Anders Bjorholm",
title="Large-Scale Data for Multiple-View Stereopsis",
journal="International Journal of Computer Vision",
year="2016",
month="Nov",
day="01",
volume="120",
number="2",
pages="153--168",
abstract="The seminal multiple-view stereo benchmark evaluations from Middlebury and by Strecha et al. have played a major role in propelling the development of multi-view stereopsis (MVS) methodology. The somewhat small size and variability of these data sets, however, limit their scope and the conclusions that can be derived from them. To facilitate further development within MVS, we here present a new and varied data set consisting of 80 scenes, seen from 49 or 64 accurate camera positions. This is accompanied by accurate structured light scans for reference and evaluation. In addition all images are taken under seven different lighting conditions. As a benchmark and to validate the use of our data set for obtaining reasonable and statistically significant findings about MVS, we have applied the three state-of-the-art MVS algorithms by Campbell et al., Furukawa et al., and Tola et al. to the data set. To do this we have extended the evaluation protocol from the Middlebury evaluation, necessitated by the more complex geometry of some of our scenes. The data set and accompanying evaluation framework are made freely available online. Based on this evaluation, we are able to observe several characteristics of state-of-the-art MVS, e.g. that there is a tradeoff between the quality of the reconstructed 3D points (accuracy) and how much of an object's surface is captured (completeness). Also, several issues that we hypothesized would challenge MVS, such as specularities and changing lighting conditions did not pose serious problems. Our study finds that the two most pressing issues for MVS are lack of texture and meshing (forming 3D points into closed triangulated surfaces).",
issn="1573-1405",
doi="10.1007/s11263-016-0902-9",
url="https://doi.org/10.1007/s11263-016-0902-9"
}

% 52 
@INPROCEEDINGS{8797791,  
author={X. {Xia} and C. {Pun} and D. {Zhang} and Y. {Yang} and H. {Lu} and H. {Gao} and F. {Xu}},  
booktitle={2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)},  
title={A 6-DOF Telexistence Drone Controlled by a Head Mounted Display},   
year={2019},  
volume={},  
number={},  
pages={1241-1242},
}

% 53
@article{CHEN1992145,
title = "Object modelling by registration of multiple range images",
journal = "Image and Vision Computing",
volume = "10",
number = "3",
pages = "145 - 155",
year = "1992",
note = "Range Image Understanding",
issn = "0262-8856",
doi = "https://doi.org/10.1016/0262-8856(92)90066-C",
url = "http://www.sciencedirect.com/science/article/pii/026288569290066C",
author = "Yang Chen and Gérard Medioni",
keywords = "object modelling, 3D surface registration, range image registration",
abstract = "We study the problem of creating a complete model of a physical object. Although this may be possible using intensity images, we here use images which directly provide access to three dimensional information. The first problem that we need to solve is to find the transformation between the different views. Previous approaches either assume this transformation to be known (which is extremely difficult for a complete model), or compute it with feature matching (which is not accurate enough for integration). In this paper, we propose a new approach which works on range data directly and registers successive views with enough overlapping area to get an accurate transformation between views. This is performed by minimizing a functional which does not require point-to-point matches. We give the details of the registration method and modelling procedure and illustrate them on real range images of complex objects."
}

% 54
@article{article,
author = {Low, Kok-Lim},
year = {2004},
month = {01},
pages = {},
title = {Linear Least-Squares Optimization for Point-to-Plane ICP Surface Registration}
}

% 55
@inproceedings{zhou2016fast,
  title={Fast global registration},
  author={Zhou, Qian-Yi and Park, Jaesik and Koltun, Vladlen},
  booktitle={European Conference on Computer Vision},
  pages={766--782},
  year={2016},
  organization={Springer}
}

%56
@article{PEDERSINI2000301,
title = "Automatic monitoring and 3D reconstruction applied to cultural heritage",
journal = "Journal of Cultural Heritage",
volume = "1",
number = "3",
pages = "301 - 313",
year = "2000",
issn = "1296-2074",
doi = "https://doi.org/10.1016/S1296-2074(00)01082-7",
url = "http://www.sciencedirect.com/science/article/pii/S1296207400010827",
author = "Federico Pedersini and Augusto Sarti and Stefano Tubaro",
keywords = "3D reconstruction, CDD-based, multi-camera acquisition, works of art",
abstract = "In this article we present our global approach to the problem of accurate 3D measurement and reconstruction of 3D works of art using a calibrated multi-camera system. In particular, we illustrate a simple and effective adaptive technique for the self-calibration of CCD-based multi-camera acquisition systems with minimum a-prior information. We also propose a general and robust approach to the problem of close-range partial 3D reconstruction of objects from stereo-correspondences. Finally, we introduce a method for performing an accurate patchworking of the partial reconstructions, based on 3D curve matching."
}

%57危险场景机器人代替人类
@article {PMID:29364873,
	Title = {Small-scale soft-bodied robot with multimodal locomotion},
	Author = {Hu, Wenqi and Lum, Guo Zhan and Mastrangeli, Massimo and Sitti, Metin},
	DOI = {10.1038/nature25443},
	Number = {7690},
	Volume = {554},
	Month = {February},
	Year = {2018},
	Journal = {Nature},
	ISSN = {0028-0836},
	Pages = {81-85},
	URL = {https://doi.org/10.1038/nature25443},
}

%58 HMD以3D形式显示
@INPROCEEDINGS{7892326,
author = {E. Z. Borba and A. Montes and R. de Deus Lopes and M. K. Zuffo and R. Kopper},
booktitle = {2017 IEEE Virtual Reality (VR)},
title = {Itapeva 3D: Being Indiana Jones in virtual reality},
year = {2017},
volume = {00},
number = {},
pages = {361-362},
keywords={Three-dimensional displays;Solid modeling;Visualization;Rocks;Virtual environments;Laser modes},
doi = {10.1109/VR.2017.7892326},
url = {doi.ieeecomputersociety.org/10.1109/VR.2017.7892326},
ISSN = {2375-5334},
month={}
}

%59  telexistence系统
@ARTICLE{734972, 
author={S. Tachi}, 
journal={IEEE Computer Graphics and Applications}, 
title={Real-time remote robotics-toward networked telexistence}, 
year={1998}, 
volume={18}, 
number={6}, 
pages={6-9}, 
keywords={telerobotics;virtual reality;real-time systems;computer networks;Internet;remote environment;remote robotics;networked telexistence;virtual reality;networked robotics;mutual telexistence;Internet;Control systems;Robotics and automation;Robot sensing systems;Computer displays;Virtual environment;Automatic control;Motion control;Pressure control;Human robot interaction;Pulse measurements}, 
doi={10.1109/38.734972}, 
ISSN={0272-1716}, 
month={Nov},}

%60 3D reconstruction applying 
@inproceedings{Wang2012COSMO,
  title={COSMO SKYMED AO PROJECTS - 3D RECONSTRUCTION AND STABILITY MONITORING OF THE THREE GORGES DAM},
  author={Wang, Zhiying and Perissin, Daniele},
  booktitle={Geoscience and Remote Sensing Symposium (IGARSS), 2012 IEEE International},
  year={2012},
}

%61HMD USING
@inproceedings{BUTTERWORTH19923DM,
  title={3DM : A three dimensional modeler using a head-mounted display},
  author={BUTTERWORTH,J.},
  booktitle={Proceedings of ACM Symposium on Interactive 3D Graphics, 1992},
  year={1992},
}

%62
@article{KerstenPotential,
  title={Potential of Automatic 3D Object Reconstruction from Multiple Images for Applications in Architecture, Cultural Heritage and Archaeology},
  author={Kersten, T. and Lindstaedt, M.},
  journal={International Journal of Heritage in the Digital Era},
  volume={1},
  number={3},
  pages={399-420},
}

%63
@inproceedings{Pittman:2014:EHT:2557500.2557527,
 author = {Pittman, Corey and LaViola,Jr., Joseph J.},
 title = {Exploring Head Tracked Head Mounted Displays for First Person Robot Teleoperation},
 booktitle = {Proceedings of the 19th International Conference on Intelligent User Interfaces},
 series = {IUI '14},
 year = {2014},
 isbn = {978-1-4503-2184-6},
 location = {Haifa, Israel},
 pages = {323--328},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/2557500.2557527},
 doi = {10.1145/2557500.2557527},
 acmid = {2557527},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {3d interaction, robots, user studies},
}

%64
@inproceedings{Ying2004Can,
  title={Can We Consider Central Catadioptric Cameras and Fisheye Cameras within a Unified Imaging Model},
  author={Ying, Xianghua and Hu, Zhanyi},
  booktitle={European Conference on Computer Vision},
  pages={442-455},
  year={2004},
}